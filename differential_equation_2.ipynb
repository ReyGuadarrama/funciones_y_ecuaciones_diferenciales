{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EkcXKXdCw6F-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ODEsolver(Sequential):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.loss_tracker = keras.metrics.Mean(name = 'my_loss')\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.loss_tracker]\n",
        "\n",
        "  def train_step(self, data):\n",
        "    batch_size = tf.shape(data)[0]\n",
        "    x = tf.random.uniform((batch_size, 1), minval = -5, maxval = 5)\n",
        "    x_o = tf.zeros((batch_size, 1))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      with tf.GradientTape() as g:\n",
        "        g.watch(x)\n",
        "        with tf.GradientTape(persistent = True) as gg:\n",
        "          gg.watch(x)\n",
        "          gg.watch(x_o)\n",
        "          y_pred = self(x, training = True)\n",
        "        dy_dx = gg.gradient(y_pred, x)\n",
        "        dy_o = gg.gradient(y_pred, x_o)\n",
        "      d2y_dx2 = g.gradient(dy_dx, x)\n",
        "      y_o = self(x_o, training = True)\n",
        "      eq = d2y_dx2 + y_pred\n",
        "      ic1 = y_o - 1\n",
        "      ic2 = dy_o + 0.5\n",
        "      loss = keras.losses.mean_squared_error(0., eq) + keras.losses.mean_squared_error(0., ic1) + keras.losses.mean_squared_error(0., ic2)      \n",
        "             \n",
        "          \n",
        "\n",
        "    grads = tape.gradient(loss, self.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "\n",
        "    self.loss_tracker.update_state(loss)\n",
        "\n",
        "    return {'my_loss': self.loss_tracker.result()}\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "8XfgvdelxFaS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ODEsolver()\n",
        "model.add(Dense(10, activation = 'tanh', input_shape = (1,)))\n",
        "model.add(Dense(8, activation = 'tanh'))\n",
        "model.add(Dense(4, activation = 'tanh'))\n",
        "model.add(Dense(1, activation = 'linear'))"
      ],
      "metadata": {
        "id": "J64N_u_qxG8X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "kxJFjx2mxIgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5736ff-7f1b-43ff-8e7c-5d1939047735"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"od_esolver_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 8)                 88        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 149\n",
            "Trainable params: 149\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(), metrics = ['my_loss'])"
      ],
      "metadata": {
        "id": "GcUM7GYaxKLx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.linspace(-5, 5, 1000)\n",
        "history = model.fit(x, epochs = 1000, verbose = 1)"
      ],
      "metadata": {
        "id": "jyHsWCeHxL2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2811d47e-4543-4788-c461-9db620208a6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "32/32 [==============================] - 1s 2ms/step - my_loss: 0.8464\n",
            "Epoch 2/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.4726\n",
            "Epoch 3/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.2828\n",
            "Epoch 4/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.2156\n",
            "Epoch 5/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1954\n",
            "Epoch 6/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1856\n",
            "Epoch 7/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1658\n",
            "Epoch 8/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1719\n",
            "Epoch 9/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1563\n",
            "Epoch 10/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1545\n",
            "Epoch 11/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1434\n",
            "Epoch 12/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1321\n",
            "Epoch 13/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1314\n",
            "Epoch 14/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1300\n",
            "Epoch 15/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1185\n",
            "Epoch 16/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1208\n",
            "Epoch 17/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1266\n",
            "Epoch 18/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1166\n",
            "Epoch 19/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1120\n",
            "Epoch 20/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1084\n",
            "Epoch 21/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1096\n",
            "Epoch 22/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1011\n",
            "Epoch 23/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1046\n",
            "Epoch 24/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0974\n",
            "Epoch 25/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1049\n",
            "Epoch 26/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1013\n",
            "Epoch 27/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1017\n",
            "Epoch 28/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.1018\n",
            "Epoch 29/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0964\n",
            "Epoch 30/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0990\n",
            "Epoch 31/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0957\n",
            "Epoch 32/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0978\n",
            "Epoch 33/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0889\n",
            "Epoch 34/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0925\n",
            "Epoch 35/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0914\n",
            "Epoch 36/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0928\n",
            "Epoch 37/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0925\n",
            "Epoch 38/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0961\n",
            "Epoch 39/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0910\n",
            "Epoch 40/1000\n",
            "32/32 [==============================] - 0s 5ms/step - my_loss: 0.0922\n",
            "Epoch 41/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 0.0862\n",
            "Epoch 42/1000\n",
            "32/32 [==============================] - 0s 4ms/step - my_loss: 0.0934\n",
            "Epoch 43/1000\n",
            "32/32 [==============================] - 0s 6ms/step - my_loss: 0.0896\n",
            "Epoch 44/1000\n",
            "32/32 [==============================] - 0s 6ms/step - my_loss: 0.0934\n",
            "Epoch 45/1000\n",
            "32/32 [==============================] - 0s 4ms/step - my_loss: 0.0890\n",
            "Epoch 46/1000\n",
            "32/32 [==============================] - 0s 5ms/step - my_loss: 0.0958\n",
            "Epoch 47/1000\n",
            "32/32 [==============================] - 0s 6ms/step - my_loss: 0.0903\n",
            "Epoch 48/1000\n",
            "32/32 [==============================] - 0s 5ms/step - my_loss: 0.0868\n",
            "Epoch 49/1000\n",
            "32/32 [==============================] - 0s 4ms/step - my_loss: 0.0893\n",
            "Epoch 50/1000\n",
            "32/32 [==============================] - 0s 5ms/step - my_loss: 0.0898\n",
            "Epoch 51/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 0.0858\n",
            "Epoch 52/1000\n",
            "32/32 [==============================] - 0s 5ms/step - my_loss: 0.0875\n",
            "Epoch 53/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 0.0929\n",
            "Epoch 54/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0897\n",
            "Epoch 55/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0896\n",
            "Epoch 56/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0887\n",
            "Epoch 57/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0870\n",
            "Epoch 58/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0906\n",
            "Epoch 59/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0918\n",
            "Epoch 60/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0865\n",
            "Epoch 61/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0867\n",
            "Epoch 62/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0871\n",
            "Epoch 63/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0871\n",
            "Epoch 64/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0850\n",
            "Epoch 65/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0868\n",
            "Epoch 66/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0812\n",
            "Epoch 67/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0818\n",
            "Epoch 68/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0864\n",
            "Epoch 69/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0861\n",
            "Epoch 70/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0831\n",
            "Epoch 71/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0817\n",
            "Epoch 72/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0827\n",
            "Epoch 73/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0782\n",
            "Epoch 74/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0804\n",
            "Epoch 75/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0772\n",
            "Epoch 76/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0758\n",
            "Epoch 77/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0709\n",
            "Epoch 78/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0702\n",
            "Epoch 79/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0715\n",
            "Epoch 80/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0683\n",
            "Epoch 81/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0654\n",
            "Epoch 82/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0693\n",
            "Epoch 83/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0683\n",
            "Epoch 84/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0609\n",
            "Epoch 85/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0649\n",
            "Epoch 86/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0604\n",
            "Epoch 87/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0622\n",
            "Epoch 88/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0599\n",
            "Epoch 89/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0565\n",
            "Epoch 90/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0563\n",
            "Epoch 91/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0559\n",
            "Epoch 92/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0516\n",
            "Epoch 93/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0493\n",
            "Epoch 94/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0533\n",
            "Epoch 95/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0483\n",
            "Epoch 96/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0531\n",
            "Epoch 97/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0472\n",
            "Epoch 98/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0452\n",
            "Epoch 99/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0465\n",
            "Epoch 100/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0466\n",
            "Epoch 101/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0438\n",
            "Epoch 102/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0451\n",
            "Epoch 103/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0419\n",
            "Epoch 104/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0466\n",
            "Epoch 105/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0444\n",
            "Epoch 106/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0412\n",
            "Epoch 107/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0421\n",
            "Epoch 108/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0436\n",
            "Epoch 109/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0437\n",
            "Epoch 110/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0394\n",
            "Epoch 111/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0381\n",
            "Epoch 112/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0372\n",
            "Epoch 113/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0384\n",
            "Epoch 114/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0381\n",
            "Epoch 115/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0393\n",
            "Epoch 116/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0345\n",
            "Epoch 117/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0352\n",
            "Epoch 118/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0360\n",
            "Epoch 119/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0349\n",
            "Epoch 120/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0379\n",
            "Epoch 121/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0356\n",
            "Epoch 122/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0315\n",
            "Epoch 123/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0374\n",
            "Epoch 124/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0341\n",
            "Epoch 125/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0338\n",
            "Epoch 126/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0351\n",
            "Epoch 127/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0345\n",
            "Epoch 128/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0339\n",
            "Epoch 129/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0334\n",
            "Epoch 130/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0344\n",
            "Epoch 131/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0313\n",
            "Epoch 132/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0328\n",
            "Epoch 133/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0314\n",
            "Epoch 134/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0324\n",
            "Epoch 135/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0323\n",
            "Epoch 136/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0312\n",
            "Epoch 137/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0298\n",
            "Epoch 138/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0289\n",
            "Epoch 139/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0300\n",
            "Epoch 140/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0287\n",
            "Epoch 141/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0268\n",
            "Epoch 142/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0277\n",
            "Epoch 143/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0293\n",
            "Epoch 144/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0266\n",
            "Epoch 145/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0256\n",
            "Epoch 146/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0248\n",
            "Epoch 147/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0252\n",
            "Epoch 148/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0270\n",
            "Epoch 149/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0259\n",
            "Epoch 150/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0247\n",
            "Epoch 151/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0217\n",
            "Epoch 152/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0212\n",
            "Epoch 153/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0236\n",
            "Epoch 154/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0215\n",
            "Epoch 155/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0224\n",
            "Epoch 156/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0203\n",
            "Epoch 157/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0189\n",
            "Epoch 158/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0199\n",
            "Epoch 159/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0180\n",
            "Epoch 160/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0160\n",
            "Epoch 161/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0175\n",
            "Epoch 162/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0162\n",
            "Epoch 163/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0166\n",
            "Epoch 164/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0134\n",
            "Epoch 165/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0135\n",
            "Epoch 166/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0127\n",
            "Epoch 167/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0121\n",
            "Epoch 168/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0112\n",
            "Epoch 169/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0110\n",
            "Epoch 170/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0100\n",
            "Epoch 171/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0085\n",
            "Epoch 172/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0081\n",
            "Epoch 173/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0073\n",
            "Epoch 174/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0076\n",
            "Epoch 175/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0064\n",
            "Epoch 176/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0062\n",
            "Epoch 177/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0060\n",
            "Epoch 178/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0063\n",
            "Epoch 179/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0058\n",
            "Epoch 180/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0053\n",
            "Epoch 181/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0049\n",
            "Epoch 182/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0052\n",
            "Epoch 183/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0048\n",
            "Epoch 184/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0044\n",
            "Epoch 185/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0043\n",
            "Epoch 186/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0043\n",
            "Epoch 187/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0040\n",
            "Epoch 188/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0042\n",
            "Epoch 189/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0040\n",
            "Epoch 190/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0040\n",
            "Epoch 191/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0039\n",
            "Epoch 192/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0039\n",
            "Epoch 193/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0037\n",
            "Epoch 194/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0036\n",
            "Epoch 195/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0034\n",
            "Epoch 196/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0032\n",
            "Epoch 197/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0029\n",
            "Epoch 198/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0030\n",
            "Epoch 199/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0032\n",
            "Epoch 200/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0036\n",
            "Epoch 201/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0035\n",
            "Epoch 202/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0028\n",
            "Epoch 203/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0031\n",
            "Epoch 204/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0030\n",
            "Epoch 205/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0024\n",
            "Epoch 206/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0029\n",
            "Epoch 207/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0025\n",
            "Epoch 208/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0030\n",
            "Epoch 209/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0029\n",
            "Epoch 210/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0026\n",
            "Epoch 211/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0029\n",
            "Epoch 212/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0028\n",
            "Epoch 213/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0025\n",
            "Epoch 214/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0024\n",
            "Epoch 215/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0023\n",
            "Epoch 216/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0025\n",
            "Epoch 217/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0026\n",
            "Epoch 218/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0023\n",
            "Epoch 219/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0022\n",
            "Epoch 220/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0022\n",
            "Epoch 221/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0020\n",
            "Epoch 222/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0022\n",
            "Epoch 223/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0021\n",
            "Epoch 224/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0023\n",
            "Epoch 225/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0022\n",
            "Epoch 226/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 0.0018\n",
            "Epoch 227/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0023\n",
            "Epoch 228/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0021\n",
            "Epoch 229/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0021\n",
            "Epoch 230/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0020\n",
            "Epoch 231/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0018\n",
            "Epoch 232/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0020\n",
            "Epoch 233/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0019\n",
            "Epoch 234/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0019\n",
            "Epoch 235/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0018\n",
            "Epoch 236/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0021\n",
            "Epoch 237/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0015\n",
            "Epoch 238/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0018\n",
            "Epoch 239/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0015\n",
            "Epoch 240/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0016\n",
            "Epoch 241/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0017\n",
            "Epoch 242/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0018\n",
            "Epoch 243/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0015\n",
            "Epoch 244/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0019\n",
            "Epoch 245/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0017\n",
            "Epoch 246/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0016\n",
            "Epoch 247/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0017\n",
            "Epoch 248/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0013\n",
            "Epoch 249/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0015\n",
            "Epoch 250/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0016\n",
            "Epoch 251/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0014\n",
            "Epoch 252/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0014\n",
            "Epoch 253/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0015\n",
            "Epoch 254/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0016\n",
            "Epoch 255/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0014\n",
            "Epoch 256/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0013\n",
            "Epoch 257/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0014\n",
            "Epoch 258/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0015\n",
            "Epoch 259/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0012\n",
            "Epoch 260/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0015\n",
            "Epoch 261/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0015\n",
            "Epoch 262/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0018\n",
            "Epoch 263/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0013\n",
            "Epoch 264/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0015\n",
            "Epoch 265/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0012\n",
            "Epoch 266/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0012\n",
            "Epoch 267/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0014\n",
            "Epoch 268/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0010\n",
            "Epoch 269/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 270/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 271/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0012\n",
            "Epoch 272/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 273/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0012\n",
            "Epoch 274/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0013\n",
            "Epoch 275/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0013\n",
            "Epoch 276/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 277/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0010\n",
            "Epoch 278/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0012\n",
            "Epoch 279/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0013\n",
            "Epoch 280/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.9517e-04\n",
            "Epoch 281/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0010\n",
            "Epoch 282/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 283/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 0.0011\n",
            "Epoch 284/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.3703e-04\n",
            "Epoch 285/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 286/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 287/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 288/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 289/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.0355e-04\n",
            "Epoch 290/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.8673e-04\n",
            "Epoch 291/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.3114e-04\n",
            "Epoch 292/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.6489e-04\n",
            "Epoch 293/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.4266e-04\n",
            "Epoch 294/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.8381e-04\n",
            "Epoch 295/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.2925e-04\n",
            "Epoch 296/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.6060e-04\n",
            "Epoch 297/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 9.3023e-04\n",
            "Epoch 298/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.5492e-04\n",
            "Epoch 299/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.0623e-04\n",
            "Epoch 300/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.3061e-04\n",
            "Epoch 301/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.2681e-04\n",
            "Epoch 302/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.4277e-04\n",
            "Epoch 303/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.2124e-04\n",
            "Epoch 304/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.5925e-04\n",
            "Epoch 305/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.7424e-04\n",
            "Epoch 306/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.6393e-04\n",
            "Epoch 307/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.4456e-04\n",
            "Epoch 308/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.9080e-04\n",
            "Epoch 309/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.3946e-04\n",
            "Epoch 310/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.2288e-04\n",
            "Epoch 311/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.0874e-04\n",
            "Epoch 312/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.1927e-04\n",
            "Epoch 313/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.5376e-04\n",
            "Epoch 314/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.5600e-04\n",
            "Epoch 315/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.5989e-04\n",
            "Epoch 316/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.4062e-04\n",
            "Epoch 317/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.2974e-04\n",
            "Epoch 318/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.9416e-04\n",
            "Epoch 319/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.3185e-04\n",
            "Epoch 320/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0010\n",
            "Epoch 321/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.8994e-04\n",
            "Epoch 322/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.3274e-04\n",
            "Epoch 323/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.9545e-04\n",
            "Epoch 324/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.7420e-04\n",
            "Epoch 325/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.6570e-04\n",
            "Epoch 326/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.8350e-04\n",
            "Epoch 327/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.4338e-04\n",
            "Epoch 328/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.6391e-04\n",
            "Epoch 329/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.0303e-04\n",
            "Epoch 330/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.0766e-04\n",
            "Epoch 331/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.1287e-04\n",
            "Epoch 332/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.5606e-04\n",
            "Epoch 333/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.7641e-04\n",
            "Epoch 334/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.8349e-04\n",
            "Epoch 335/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.2729e-04\n",
            "Epoch 336/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.9461e-04\n",
            "Epoch 337/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 0.0011\n",
            "Epoch 338/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.4673e-04\n",
            "Epoch 339/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.5169e-04\n",
            "Epoch 340/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.9565e-04\n",
            "Epoch 341/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.7617e-04\n",
            "Epoch 342/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.5168e-04\n",
            "Epoch 343/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.9147e-04\n",
            "Epoch 344/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.2900e-04\n",
            "Epoch 345/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.7955e-04\n",
            "Epoch 346/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8765e-04\n",
            "Epoch 347/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.3260e-04\n",
            "Epoch 348/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8271e-04\n",
            "Epoch 349/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.8005e-04\n",
            "Epoch 350/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.1629e-04\n",
            "Epoch 351/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.1959e-04\n",
            "Epoch 352/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.6126e-04\n",
            "Epoch 353/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4481e-04\n",
            "Epoch 354/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.5821e-04\n",
            "Epoch 355/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8144e-04\n",
            "Epoch 356/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.9149e-04\n",
            "Epoch 357/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4756e-04\n",
            "Epoch 358/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.7344e-04\n",
            "Epoch 359/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.7284e-04\n",
            "Epoch 360/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.6409e-04\n",
            "Epoch 361/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8278e-04\n",
            "Epoch 362/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.6911e-04\n",
            "Epoch 363/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.0902e-04\n",
            "Epoch 364/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.5993e-04\n",
            "Epoch 365/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.0310e-04\n",
            "Epoch 366/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.9840e-04\n",
            "Epoch 367/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.0817e-04\n",
            "Epoch 368/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.7470e-04\n",
            "Epoch 369/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8415e-04\n",
            "Epoch 370/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.6507e-04\n",
            "Epoch 371/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8545e-04\n",
            "Epoch 372/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1999e-04\n",
            "Epoch 373/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.9474e-04\n",
            "Epoch 374/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4349e-04\n",
            "Epoch 375/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.5141e-04\n",
            "Epoch 376/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4621e-04\n",
            "Epoch 377/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.8165e-04\n",
            "Epoch 378/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6605e-04\n",
            "Epoch 379/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1627e-04\n",
            "Epoch 380/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.9924e-04\n",
            "Epoch 381/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6964e-04\n",
            "Epoch 382/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2345e-04\n",
            "Epoch 383/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.3598e-04\n",
            "Epoch 384/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8226e-04\n",
            "Epoch 385/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.3026e-04\n",
            "Epoch 386/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3450e-04\n",
            "Epoch 387/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6499e-04\n",
            "Epoch 388/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6212e-04\n",
            "Epoch 389/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.3936e-04\n",
            "Epoch 390/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6858e-04\n",
            "Epoch 391/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.0254e-04\n",
            "Epoch 392/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1300e-04\n",
            "Epoch 393/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9300e-04\n",
            "Epoch 394/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1803e-04\n",
            "Epoch 395/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.8531e-04\n",
            "Epoch 396/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6378e-04\n",
            "Epoch 397/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7508e-04\n",
            "Epoch 398/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6890e-04\n",
            "Epoch 399/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4737e-04\n",
            "Epoch 400/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.0064e-04\n",
            "Epoch 401/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9470e-04\n",
            "Epoch 402/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8710e-04\n",
            "Epoch 403/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4976e-04\n",
            "Epoch 404/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4936e-04\n",
            "Epoch 405/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9258e-04\n",
            "Epoch 406/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6517e-04\n",
            "Epoch 407/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1226e-04\n",
            "Epoch 408/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8831e-04\n",
            "Epoch 409/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5303e-04\n",
            "Epoch 410/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1078e-04\n",
            "Epoch 411/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5141e-04\n",
            "Epoch 412/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2248e-04\n",
            "Epoch 413/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.0000e-04\n",
            "Epoch 414/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4137e-04\n",
            "Epoch 415/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5383e-04\n",
            "Epoch 416/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9513e-04\n",
            "Epoch 417/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7839e-04\n",
            "Epoch 418/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5957e-04\n",
            "Epoch 419/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4449e-04\n",
            "Epoch 420/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7123e-04\n",
            "Epoch 421/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.4013e-04\n",
            "Epoch 422/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7775e-04\n",
            "Epoch 423/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6004e-04\n",
            "Epoch 424/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8700e-04\n",
            "Epoch 425/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9148e-04\n",
            "Epoch 426/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3781e-04\n",
            "Epoch 427/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2675e-04\n",
            "Epoch 428/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6854e-04\n",
            "Epoch 429/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9441e-04\n",
            "Epoch 430/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5067e-04\n",
            "Epoch 431/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6925e-04\n",
            "Epoch 432/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3703e-04\n",
            "Epoch 433/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.5745e-04\n",
            "Epoch 434/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.5673e-04\n",
            "Epoch 435/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6118e-04\n",
            "Epoch 436/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0163e-04\n",
            "Epoch 437/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6193e-04\n",
            "Epoch 438/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7525e-04\n",
            "Epoch 439/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0474e-04\n",
            "Epoch 440/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9760e-04\n",
            "Epoch 441/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7114e-04\n",
            "Epoch 442/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7471e-04\n",
            "Epoch 443/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1913e-04\n",
            "Epoch 444/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1555e-04\n",
            "Epoch 445/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.0207e-04\n",
            "Epoch 446/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0148e-04\n",
            "Epoch 447/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9493e-04\n",
            "Epoch 448/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8503e-04\n",
            "Epoch 449/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9830e-04\n",
            "Epoch 450/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9362e-04\n",
            "Epoch 451/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5424e-04\n",
            "Epoch 452/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2095e-04\n",
            "Epoch 453/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.5763e-04\n",
            "Epoch 454/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.3819e-04\n",
            "Epoch 455/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.2453e-04\n",
            "Epoch 456/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.3227e-04\n",
            "Epoch 457/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.2609e-04\n",
            "Epoch 458/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.2784e-04\n",
            "Epoch 459/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.2137e-04\n",
            "Epoch 460/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1857e-04\n",
            "Epoch 461/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7042e-04\n",
            "Epoch 462/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6641e-04\n",
            "Epoch 463/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8706e-04\n",
            "Epoch 464/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.5349e-04\n",
            "Epoch 465/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.2348e-04\n",
            "Epoch 466/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.3825e-04\n",
            "Epoch 467/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.4743e-04\n",
            "Epoch 468/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.1276e-04\n",
            "Epoch 469/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8368e-04\n",
            "Epoch 470/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1443e-04\n",
            "Epoch 471/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0951e-04\n",
            "Epoch 472/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.4570e-04\n",
            "Epoch 473/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1422e-04\n",
            "Epoch 474/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.2368e-04\n",
            "Epoch 475/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0844e-04\n",
            "Epoch 476/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8817e-04\n",
            "Epoch 477/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0618e-04\n",
            "Epoch 478/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0112e-04\n",
            "Epoch 479/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.2870e-04\n",
            "Epoch 480/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6654e-04\n",
            "Epoch 481/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1474e-04\n",
            "Epoch 482/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0842e-04\n",
            "Epoch 483/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1429e-04\n",
            "Epoch 484/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.2763e-05\n",
            "Epoch 485/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.0724e-05\n",
            "Epoch 486/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 9.7246e-05\n",
            "Epoch 487/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.1022e-04\n",
            "Epoch 488/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.4187e-04\n",
            "Epoch 489/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.6292e-05\n",
            "Epoch 490/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0097e-04\n",
            "Epoch 491/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.4062e-04\n",
            "Epoch 492/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0823e-04\n",
            "Epoch 493/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.4082e-05\n",
            "Epoch 494/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.4706e-05\n",
            "Epoch 495/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.6187e-05\n",
            "Epoch 496/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.5749e-05\n",
            "Epoch 497/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.6586e-05\n",
            "Epoch 498/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.1358e-05\n",
            "Epoch 499/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.0506e-05\n",
            "Epoch 500/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1096e-04\n",
            "Epoch 501/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0823e-04\n",
            "Epoch 502/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.9330e-05\n",
            "Epoch 503/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 7.3576e-05\n",
            "Epoch 504/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 8.3114e-05\n",
            "Epoch 505/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.9789e-05\n",
            "Epoch 506/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1751e-04\n",
            "Epoch 507/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.4776e-05\n",
            "Epoch 508/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.0716e-05\n",
            "Epoch 509/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 8.5919e-05\n",
            "Epoch 510/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.0396e-04\n",
            "Epoch 511/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.2986e-04\n",
            "Epoch 512/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.7256e-05\n",
            "Epoch 513/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.4548e-05\n",
            "Epoch 514/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.3847e-05\n",
            "Epoch 515/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.7094e-05\n",
            "Epoch 516/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 7.7247e-05\n",
            "Epoch 517/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.1024e-05\n",
            "Epoch 518/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0068e-04\n",
            "Epoch 519/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.5871e-04\n",
            "Epoch 520/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.5147e-05\n",
            "Epoch 521/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.1567e-05\n",
            "Epoch 522/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.2965e-05\n",
            "Epoch 523/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1655e-04\n",
            "Epoch 524/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.8145e-05\n",
            "Epoch 525/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.4684e-05\n",
            "Epoch 526/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.7639e-05\n",
            "Epoch 527/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.5317e-05\n",
            "Epoch 528/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.4548e-05\n",
            "Epoch 529/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1867e-04\n",
            "Epoch 530/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.7185e-05\n",
            "Epoch 531/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.0471e-05\n",
            "Epoch 532/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.4763e-05\n",
            "Epoch 533/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.9022e-05\n",
            "Epoch 534/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.6264e-05\n",
            "Epoch 535/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 6.3947e-05\n",
            "Epoch 536/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.7183e-05\n",
            "Epoch 537/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.9983e-05\n",
            "Epoch 538/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.0138e-05\n",
            "Epoch 539/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0143e-04\n",
            "Epoch 540/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9093e-04\n",
            "Epoch 541/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.4704e-04\n",
            "Epoch 542/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0320e-04\n",
            "Epoch 543/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.1363e-05\n",
            "Epoch 544/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.2492e-05\n",
            "Epoch 545/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 9.0243e-05\n",
            "Epoch 546/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1498e-04\n",
            "Epoch 547/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.2299e-05\n",
            "Epoch 548/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.5518e-04\n",
            "Epoch 549/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.2913e-05\n",
            "Epoch 550/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.2012e-05\n",
            "Epoch 551/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.6560e-05\n",
            "Epoch 552/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.5024e-05\n",
            "Epoch 553/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.1338e-05\n",
            "Epoch 554/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.0312e-05\n",
            "Epoch 555/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.4630e-05\n",
            "Epoch 556/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.3760e-05\n",
            "Epoch 557/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 5.3376e-05\n",
            "Epoch 558/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.6574e-05\n",
            "Epoch 559/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.0018e-05\n",
            "Epoch 560/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.2224e-05\n",
            "Epoch 561/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.5744e-05\n",
            "Epoch 562/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.3783e-05\n",
            "Epoch 563/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3615e-05\n",
            "Epoch 564/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.1035e-05\n",
            "Epoch 565/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.1313e-05\n",
            "Epoch 566/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1276e-04\n",
            "Epoch 567/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.5192e-05\n",
            "Epoch 568/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.9280e-05\n",
            "Epoch 569/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3765e-05\n",
            "Epoch 570/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.3504e-05\n",
            "Epoch 571/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.0030e-05\n",
            "Epoch 572/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.7162e-05\n",
            "Epoch 573/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.0370e-05\n",
            "Epoch 574/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.6460e-05\n",
            "Epoch 575/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3971e-05\n",
            "Epoch 576/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.6271e-05\n",
            "Epoch 577/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.4410e-05\n",
            "Epoch 578/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0689e-04\n",
            "Epoch 579/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.1868e-04\n",
            "Epoch 580/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.5096e-04\n",
            "Epoch 581/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.4996e-05\n",
            "Epoch 582/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.5847e-05\n",
            "Epoch 583/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.9168e-05\n",
            "Epoch 584/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.7361e-05\n",
            "Epoch 585/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.3167e-05\n",
            "Epoch 586/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.6733e-05\n",
            "Epoch 587/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.0660e-05\n",
            "Epoch 588/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.0242e-05\n",
            "Epoch 589/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.8710e-05\n",
            "Epoch 590/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.0927e-05\n",
            "Epoch 591/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.8498e-05\n",
            "Epoch 592/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8090e-05\n",
            "Epoch 593/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4607e-05\n",
            "Epoch 594/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6076e-05\n",
            "Epoch 595/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1256e-05\n",
            "Epoch 596/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.0529e-05\n",
            "Epoch 597/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3448e-05\n",
            "Epoch 598/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.8355e-05\n",
            "Epoch 599/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7119e-05\n",
            "Epoch 600/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.1342e-05\n",
            "Epoch 601/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 8.9285e-05\n",
            "Epoch 602/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.9298e-05\n",
            "Epoch 603/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1835e-05\n",
            "Epoch 604/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.0159e-05\n",
            "Epoch 605/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.3831e-05\n",
            "Epoch 606/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1742e-05\n",
            "Epoch 607/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.0706e-05\n",
            "Epoch 608/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.4397e-05\n",
            "Epoch 609/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.8893e-05\n",
            "Epoch 610/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.9148e-05\n",
            "Epoch 611/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6133e-05\n",
            "Epoch 612/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.7196e-05\n",
            "Epoch 613/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.9345e-05\n",
            "Epoch 614/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1063e-05\n",
            "Epoch 615/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7147e-04\n",
            "Epoch 616/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.9094e-04\n",
            "Epoch 617/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9144e-04\n",
            "Epoch 618/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3215e-05\n",
            "Epoch 619/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.8777e-05\n",
            "Epoch 620/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.2989e-05\n",
            "Epoch 621/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.2908e-05\n",
            "Epoch 622/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.4047e-05\n",
            "Epoch 623/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.5688e-05\n",
            "Epoch 624/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.7374e-05\n",
            "Epoch 625/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1579e-05\n",
            "Epoch 626/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.5261e-05\n",
            "Epoch 627/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3568e-05\n",
            "Epoch 628/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.7945e-05\n",
            "Epoch 629/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9666e-05\n",
            "Epoch 630/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.5913e-05\n",
            "Epoch 631/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8681e-05\n",
            "Epoch 632/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8721e-05\n",
            "Epoch 633/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4043e-05\n",
            "Epoch 634/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.7525e-05\n",
            "Epoch 635/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.7987e-05\n",
            "Epoch 636/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.5720e-05\n",
            "Epoch 637/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.7002e-05\n",
            "Epoch 638/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.8434e-05\n",
            "Epoch 639/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.5909e-05\n",
            "Epoch 640/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1916e-05\n",
            "Epoch 641/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.1824e-05\n",
            "Epoch 642/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8792e-05\n",
            "Epoch 643/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8907e-05\n",
            "Epoch 644/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8546e-05\n",
            "Epoch 645/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5299e-05\n",
            "Epoch 646/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.9352e-05\n",
            "Epoch 647/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.2285e-05\n",
            "Epoch 648/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.2464e-05\n",
            "Epoch 649/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.8759e-05\n",
            "Epoch 650/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.7979e-05\n",
            "Epoch 651/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.6474e-05\n",
            "Epoch 652/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1103e-05\n",
            "Epoch 653/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 6.5409e-05\n",
            "Epoch 654/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.3331e-05\n",
            "Epoch 655/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.5822e-05\n",
            "Epoch 656/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.2309e-05\n",
            "Epoch 657/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.4112e-05\n",
            "Epoch 658/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.1613e-05\n",
            "Epoch 659/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.0841e-05\n",
            "Epoch 660/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1811e-05\n",
            "Epoch 661/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6615e-05\n",
            "Epoch 662/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6955e-05\n",
            "Epoch 663/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.0194e-05\n",
            "Epoch 664/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6327e-05\n",
            "Epoch 665/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.5155e-05\n",
            "Epoch 666/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.1121e-04\n",
            "Epoch 667/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.9226e-05\n",
            "Epoch 668/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.0549e-05\n",
            "Epoch 669/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.6125e-05\n",
            "Epoch 670/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4398e-05\n",
            "Epoch 671/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.8187e-05\n",
            "Epoch 672/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2748e-05\n",
            "Epoch 673/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.0868e-05\n",
            "Epoch 674/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1599e-05\n",
            "Epoch 675/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9840e-05\n",
            "Epoch 676/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2209e-05\n",
            "Epoch 677/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.6204e-05\n",
            "Epoch 678/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.8581e-05\n",
            "Epoch 679/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.7537e-05\n",
            "Epoch 680/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.3386e-05\n",
            "Epoch 681/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8714e-05\n",
            "Epoch 682/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0884e-05\n",
            "Epoch 683/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8120e-05\n",
            "Epoch 684/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.7336e-05\n",
            "Epoch 685/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8244e-05\n",
            "Epoch 686/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1180e-05\n",
            "Epoch 687/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.3248e-05\n",
            "Epoch 688/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.0454e-05\n",
            "Epoch 689/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.8229e-05\n",
            "Epoch 690/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.8947e-05\n",
            "Epoch 691/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 8.6509e-05\n",
            "Epoch 692/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.7169e-05\n",
            "Epoch 693/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.7755e-05\n",
            "Epoch 694/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2404e-05\n",
            "Epoch 695/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4709e-05\n",
            "Epoch 696/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3537e-05\n",
            "Epoch 697/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.3704e-05\n",
            "Epoch 698/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.7211e-05\n",
            "Epoch 699/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.7881e-05\n",
            "Epoch 700/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.7498e-05\n",
            "Epoch 701/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.6053e-05\n",
            "Epoch 702/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.3047e-05\n",
            "Epoch 703/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.9601e-05\n",
            "Epoch 704/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.5309e-05\n",
            "Epoch 705/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1806e-05\n",
            "Epoch 706/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6616e-05\n",
            "Epoch 707/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.6875e-05\n",
            "Epoch 708/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3202e-05\n",
            "Epoch 709/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1671e-05\n",
            "Epoch 710/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.0408e-05\n",
            "Epoch 711/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7688e-05\n",
            "Epoch 712/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2932e-05\n",
            "Epoch 713/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6406e-05\n",
            "Epoch 714/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.1853e-05\n",
            "Epoch 715/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.5092e-05\n",
            "Epoch 716/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.2509e-05\n",
            "Epoch 717/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1782e-05\n",
            "Epoch 718/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.0645e-05\n",
            "Epoch 719/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8253e-05\n",
            "Epoch 720/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4997e-05\n",
            "Epoch 721/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.6237e-05\n",
            "Epoch 722/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8878e-05\n",
            "Epoch 723/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9766e-05\n",
            "Epoch 724/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1204e-05\n",
            "Epoch 725/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6161e-05\n",
            "Epoch 726/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1966e-05\n",
            "Epoch 727/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.4555e-05\n",
            "Epoch 728/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9484e-05\n",
            "Epoch 729/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1910e-05\n",
            "Epoch 730/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.4463e-05\n",
            "Epoch 731/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.5502e-05\n",
            "Epoch 732/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.0031e-05\n",
            "Epoch 733/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9510e-04\n",
            "Epoch 734/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6917e-04\n",
            "Epoch 735/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9058e-05\n",
            "Epoch 736/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2385e-05\n",
            "Epoch 737/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.2828e-05\n",
            "Epoch 738/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.1479e-04\n",
            "Epoch 739/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 6.3292e-05\n",
            "Epoch 740/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4620e-05\n",
            "Epoch 741/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2569e-05\n",
            "Epoch 742/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1132e-05\n",
            "Epoch 743/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8524e-05\n",
            "Epoch 744/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.7793e-05\n",
            "Epoch 745/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.6583e-05\n",
            "Epoch 746/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8180e-05\n",
            "Epoch 747/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5427e-05\n",
            "Epoch 748/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.5707e-05\n",
            "Epoch 749/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1212e-05\n",
            "Epoch 750/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.2772e-05\n",
            "Epoch 751/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.1240e-05\n",
            "Epoch 752/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.4837e-05\n",
            "Epoch 753/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3875e-05\n",
            "Epoch 754/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9805e-05\n",
            "Epoch 755/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6245e-05\n",
            "Epoch 756/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5483e-05\n",
            "Epoch 757/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.9832e-05\n",
            "Epoch 758/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.0148e-05\n",
            "Epoch 759/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 8.4893e-05\n",
            "Epoch 760/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.3136e-05\n",
            "Epoch 761/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.1470e-05\n",
            "Epoch 762/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.9469e-05\n",
            "Epoch 763/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0425e-05\n",
            "Epoch 764/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2040e-05\n",
            "Epoch 765/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.9725e-05\n",
            "Epoch 766/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.3097e-04\n",
            "Epoch 767/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.5305e-04\n",
            "Epoch 768/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.6865e-05\n",
            "Epoch 769/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6254e-05\n",
            "Epoch 770/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4912e-05\n",
            "Epoch 771/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1673e-05\n",
            "Epoch 772/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1465e-05\n",
            "Epoch 773/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7760e-05\n",
            "Epoch 774/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8148e-05\n",
            "Epoch 775/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.8181e-05\n",
            "Epoch 776/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.1819e-05\n",
            "Epoch 777/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.7917e-05\n",
            "Epoch 778/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0487e-05\n",
            "Epoch 779/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.2671e-05\n",
            "Epoch 780/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.2877e-05\n",
            "Epoch 781/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2681e-05\n",
            "Epoch 782/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8621e-05\n",
            "Epoch 783/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8086e-05\n",
            "Epoch 784/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4700e-05\n",
            "Epoch 785/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.9072e-05\n",
            "Epoch 786/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.9199e-05\n",
            "Epoch 787/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8167e-05\n",
            "Epoch 788/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5069e-05\n",
            "Epoch 789/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.2605e-05\n",
            "Epoch 790/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1394e-05\n",
            "Epoch 791/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1601e-05\n",
            "Epoch 792/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.0631e-05\n",
            "Epoch 793/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4396e-05\n",
            "Epoch 794/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5065e-05\n",
            "Epoch 795/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6870e-05\n",
            "Epoch 796/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4731e-05\n",
            "Epoch 797/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 5.5939e-05\n",
            "Epoch 798/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8025e-05\n",
            "Epoch 799/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.3649e-05\n",
            "Epoch 800/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.3304e-05\n",
            "Epoch 801/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3339e-05\n",
            "Epoch 802/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.4846e-05\n",
            "Epoch 803/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.2627e-05\n",
            "Epoch 804/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5724e-05\n",
            "Epoch 805/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.6702e-05\n",
            "Epoch 806/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.5745e-05\n",
            "Epoch 807/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.9968e-05\n",
            "Epoch 808/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 5.7035e-05\n",
            "Epoch 809/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3071e-05\n",
            "Epoch 810/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.1463e-05\n",
            "Epoch 811/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.6278e-05\n",
            "Epoch 812/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1746e-05\n",
            "Epoch 813/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.5104e-05\n",
            "Epoch 814/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.2652e-05\n",
            "Epoch 815/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4678e-05\n",
            "Epoch 816/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.0207e-05\n",
            "Epoch 817/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8906e-05\n",
            "Epoch 818/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1453e-05\n",
            "Epoch 819/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.9766e-05\n",
            "Epoch 820/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.4689e-05\n",
            "Epoch 821/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.5869e-05\n",
            "Epoch 822/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6206e-05\n",
            "Epoch 823/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7696e-05\n",
            "Epoch 824/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2676e-05\n",
            "Epoch 825/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.7720e-05\n",
            "Epoch 826/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5300e-05\n",
            "Epoch 827/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4157e-05\n",
            "Epoch 828/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6890e-05\n",
            "Epoch 829/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2470e-05\n",
            "Epoch 830/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.1652e-05\n",
            "Epoch 831/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.6739e-05\n",
            "Epoch 832/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.1377e-04\n",
            "Epoch 833/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5883e-04\n",
            "Epoch 834/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.5871e-05\n",
            "Epoch 835/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4249e-05\n",
            "Epoch 836/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3106e-05\n",
            "Epoch 837/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.5055e-05\n",
            "Epoch 838/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.4134e-05\n",
            "Epoch 839/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1463e-05\n",
            "Epoch 840/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.4226e-05\n",
            "Epoch 841/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.2533e-04\n",
            "Epoch 842/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 8.0543e-05\n",
            "Epoch 843/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.2656e-05\n",
            "Epoch 844/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.0027e-05\n",
            "Epoch 845/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.3209e-05\n",
            "Epoch 846/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7588e-05\n",
            "Epoch 847/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.2083e-05\n",
            "Epoch 848/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.8586e-05\n",
            "Epoch 849/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.1334e-05\n",
            "Epoch 850/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.8908e-05\n",
            "Epoch 851/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9466e-05\n",
            "Epoch 852/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0085e-05\n",
            "Epoch 853/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.7249e-05\n",
            "Epoch 854/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0179e-05\n",
            "Epoch 855/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.3721e-05\n",
            "Epoch 856/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 7.7271e-05\n",
            "Epoch 857/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.4798e-05\n",
            "Epoch 858/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3048e-05\n",
            "Epoch 859/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7587e-05\n",
            "Epoch 860/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2741e-05\n",
            "Epoch 861/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2721e-05\n",
            "Epoch 862/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.5323e-05\n",
            "Epoch 863/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.9788e-05\n",
            "Epoch 864/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.1979e-05\n",
            "Epoch 865/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6906e-05\n",
            "Epoch 866/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9193e-05\n",
            "Epoch 867/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9128e-05\n",
            "Epoch 868/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4366e-05\n",
            "Epoch 869/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.6003e-05\n",
            "Epoch 870/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6078e-05\n",
            "Epoch 871/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3045e-05\n",
            "Epoch 872/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6652e-05\n",
            "Epoch 873/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0948e-05\n",
            "Epoch 874/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9823e-05\n",
            "Epoch 875/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.5420e-05\n",
            "Epoch 876/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.5208e-05\n",
            "Epoch 877/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8907e-05\n",
            "Epoch 878/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.9177e-05\n",
            "Epoch 879/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0327e-04\n",
            "Epoch 880/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.5441e-05\n",
            "Epoch 881/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.1938e-05\n",
            "Epoch 882/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2551e-05\n",
            "Epoch 883/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7384e-05\n",
            "Epoch 884/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.6125e-05\n",
            "Epoch 885/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.7904e-05\n",
            "Epoch 886/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.1310e-05\n",
            "Epoch 887/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 5.0587e-05\n",
            "Epoch 888/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.1792e-05\n",
            "Epoch 889/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 6.2077e-05\n",
            "Epoch 890/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8996e-05\n",
            "Epoch 891/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 9.0218e-05\n",
            "Epoch 892/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.7113e-05\n",
            "Epoch 893/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6090e-05\n",
            "Epoch 894/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.1451e-05\n",
            "Epoch 895/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7806e-05\n",
            "Epoch 896/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.9536e-05\n",
            "Epoch 897/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.4076e-05\n",
            "Epoch 898/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6477e-05\n",
            "Epoch 899/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7336e-05\n",
            "Epoch 900/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.5717e-05\n",
            "Epoch 901/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.5235e-05\n",
            "Epoch 902/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2505e-05\n",
            "Epoch 903/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.5240e-05\n",
            "Epoch 904/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.9564e-05\n",
            "Epoch 905/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5733e-05\n",
            "Epoch 906/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0878e-05\n",
            "Epoch 907/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.8947e-05\n",
            "Epoch 908/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.2883e-05\n",
            "Epoch 909/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 5.9147e-05\n",
            "Epoch 910/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.4719e-05\n",
            "Epoch 911/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8951e-05\n",
            "Epoch 912/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5207e-05\n",
            "Epoch 913/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7068e-05\n",
            "Epoch 914/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2028e-05\n",
            "Epoch 915/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.0149e-05\n",
            "Epoch 916/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 8.4188e-05\n",
            "Epoch 917/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6431e-04\n",
            "Epoch 918/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.4233e-05\n",
            "Epoch 919/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7770e-05\n",
            "Epoch 920/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2175e-05\n",
            "Epoch 921/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.9432e-05\n",
            "Epoch 922/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.5900e-05\n",
            "Epoch 923/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.9232e-05\n",
            "Epoch 924/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9763e-05\n",
            "Epoch 925/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.4443e-05\n",
            "Epoch 926/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.8779e-05\n",
            "Epoch 927/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.1726e-05\n",
            "Epoch 928/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.5936e-05\n",
            "Epoch 929/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 8.3065e-05\n",
            "Epoch 930/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.0714e-05\n",
            "Epoch 931/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.7684e-05\n",
            "Epoch 932/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.9862e-05\n",
            "Epoch 933/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.2609e-04\n",
            "Epoch 934/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.8410e-05\n",
            "Epoch 935/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6608e-05\n",
            "Epoch 936/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.7761e-05\n",
            "Epoch 937/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8594e-04\n",
            "Epoch 938/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 5.3793e-05\n",
            "Epoch 939/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3836e-05\n",
            "Epoch 940/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.8585e-05\n",
            "Epoch 941/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.5095e-05\n",
            "Epoch 942/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.4835e-05\n",
            "Epoch 943/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7940e-05\n",
            "Epoch 944/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6032e-05\n",
            "Epoch 945/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.2671e-05\n",
            "Epoch 946/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.0286e-05\n",
            "Epoch 947/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.8555e-05\n",
            "Epoch 948/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6431e-05\n",
            "Epoch 949/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.1501e-05\n",
            "Epoch 950/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.2662e-05\n",
            "Epoch 951/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.5881e-05\n",
            "Epoch 952/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.2225e-05\n",
            "Epoch 953/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7627e-05\n",
            "Epoch 954/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.0341e-05\n",
            "Epoch 955/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.9032e-05\n",
            "Epoch 956/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6480e-05\n",
            "Epoch 957/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.6252e-05\n",
            "Epoch 958/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.5712e-05\n",
            "Epoch 959/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.9730e-05\n",
            "Epoch 960/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.7430e-05\n",
            "Epoch 961/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.2090e-05\n",
            "Epoch 962/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.6700e-05\n",
            "Epoch 963/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.2394e-05\n",
            "Epoch 964/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 5.0209e-05\n",
            "Epoch 965/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.6788e-05\n",
            "Epoch 966/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 5.5716e-05\n",
            "Epoch 967/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.9866e-05\n",
            "Epoch 968/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.4936e-05\n",
            "Epoch 969/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.2988e-05\n",
            "Epoch 970/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.8329e-05\n",
            "Epoch 971/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 7.1873e-05\n",
            "Epoch 972/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 5.1850e-05\n",
            "Epoch 973/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.5091e-05\n",
            "Epoch 974/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.7179e-05\n",
            "Epoch 975/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8160e-05\n",
            "Epoch 976/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.2868e-05\n",
            "Epoch 977/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.0516e-05\n",
            "Epoch 978/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3885e-05\n",
            "Epoch 979/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.8491e-05\n",
            "Epoch 980/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.5328e-05\n",
            "Epoch 981/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 4.6292e-05\n",
            "Epoch 982/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.5218e-05\n",
            "Epoch 983/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 3.9407e-05\n",
            "Epoch 984/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.6784e-05\n",
            "Epoch 985/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.8916e-05\n",
            "Epoch 986/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 6.7469e-05\n",
            "Epoch 987/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 1.0211e-04\n",
            "Epoch 988/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 9.7499e-05\n",
            "Epoch 989/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 7.0868e-05\n",
            "Epoch 990/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 4.0603e-05\n",
            "Epoch 991/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 1.3422e-05\n",
            "Epoch 992/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.0953e-05\n",
            "Epoch 993/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 8.3199e-05\n",
            "Epoch 994/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.5562e-05\n",
            "Epoch 995/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.8391e-05\n",
            "Epoch 996/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.0359e-05\n",
            "Epoch 997/1000\n",
            "32/32 [==============================] - 0s 2ms/step - my_loss: 2.3678e-05\n",
            "Epoch 998/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 2.3844e-05\n",
            "Epoch 999/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 5.0838e-05\n",
            "Epoch 1000/1000\n",
            "32/32 [==============================] - 0s 3ms/step - my_loss: 3.1865e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['my_loss']\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "epoch = range(1,len(loss_values)+1)\n",
        "plt.plot(epoch,loss_values, 'o',label='training')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "PrbaI4vDxNzh",
        "outputId": "155a40aa-647c-4fdc-f7ce-6eb9945e8615"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def solution_2(x):\n",
        "  return np.cos(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "NWXlJf9bxP8Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = tf.linspace(-5, 5, 1000)\n",
        "a = model.predict(x_test)\n",
        "plt.plot(x_test, a, label = 'neural approach')\n",
        "plt.plot(x_test, solution_2(x_test), label = 'real function')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "A-G37oX5xRau",
        "outputId": "6ceaeccc-16a4-499e-99af-4a41bc81e4ea"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}